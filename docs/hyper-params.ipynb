{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(hyper-params)=\n",
    "# Hyperparameter tuning optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLRun supports iterative tasks for automatic and distributed execution of many tasks with variable parameters (hyperparams). Iterative tasks can be distributed across multiple containers. They can be used for:\n",
    "* Parallel loading and preparation of many data objects\n",
    "* Model training with different parameter sets and/or algorithms\n",
    "* Parallel testing with many test vector options\n",
    "* AutoML\n",
    "\n",
    "MLRun iterations can be viewed as child runs under the main task/run. Each child run gets a set of parameters that are computed/selected from the input hyperparameters based on the chosen strategy ([Grid](#grid-search-default), [List](#list-search), [Random](#random-search) or [Custom](#custom-iterator)).\n",
    "\n",
    "The different iterations can run in parallel over multiple containers (using Dask or Nuclio runtimes, which manage the workers). Read more in [Parallel execution over containers](#parallel-execution-over-containers).\n",
    "\n",
    "The hyperparameters and options are specified in the `task` or the {py:meth}`~mlrun.runtimes.BaseRuntime.run` command \n",
    "through the `hyperparams` (for hyperparam values) and `hyper_param_options` (for \n",
    "{py:class}`~mlrun.model.HyperParamOptions`) properties. See the examples below. \n",
    "\n",
    "The hyperparams are specified as a struct of `key: list` values. The values can be of any type (int, string, float, ..). \n",
    "The lists are used to compute the parameter combinations using one of the \n",
    "following strategies: \n",
    "- [Grid search](#grid-search-default) (`grid`) &mdash; running all the parameter combinations. The `key: list` values structure is similar to: \n",
    "  ` { \"p1\": [1,2], \"p2\": [2,4] }`<br>\n",
    "   The result is the four iterations with all the combinations of p1 and p2. \n",
    "   Hyperparameters can also be loaded directly from a JSON file (specify `param_file` in {py:class}`~mlrun.model.HyperParamOptions`).\n",
    "- [Random](#random-search) (`random`) &mdash; running a sampled set from all the parameter combinations. Hyperparameters can       also be loaded directly from a JSON file, the same as `grid`.\n",
    "- [List](#list-search) (`list`) &mdash; running the first parameter from each list followed by the second from each list and so on. **All the lists must be of equal length**. Hyperparameters can also be loaded directly from a JSON or CSV file containing a list of the iterations to be executed. Example JSON: `{\"p1\": [1], \"p2\": [10]}` (specify `param_file` in {py:class}`~mlrun.model.HyperParamOptions`).\n",
    "\n",
    "You can specify a selection criteria to select the best run among the different child runs by setting the `selector` option. This marks the selected result as the parent (iteration 0) result, and marks the best result in the user interface.\n",
    "\n",
    "You can also specify the `stop_condition` to stop the execution of child runs when some criteria, based on the returned results, is met (for example `stop_condition=\"accuracy>=0.9\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this section**\n",
    "- [Basic code](#basic-code)\n",
    "- [Review the results](#Review-the-results)\n",
    "- [Examples](#examples)\n",
    "- [Parallel execution over containers](#parallel-execution-over-containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic code\n",
    "\n",
    "Here's a basic example of running multiple jobs in parallel for **hyperparameters tuning**, selecting the best run with respect to the `max accuracy`. \n",
    "\n",
    "Run the hyperparameters tuning job by using the keywords arguments: \n",
    "\n",
    "* `hyperparams` for the hyperparameters options and values of choice.\n",
    "* `selector` for specifying how to select the best model.\n",
    "\n",
    "```python\n",
    "hp_tuning_run = project.run_function(\n",
    "    \"trainer\", \n",
    "    inputs={\"dataset\": gen_data_run.outputs[\"dataset\"]}, \n",
    "    hyperparams={\n",
    "        \"n_estimators\": [100, 500, 1000], \n",
    "        \"max_depth\": [5, 15, 30]\n",
    "    }, \n",
    "    selector=\"max.accuracy\", \n",
    "    local=True\n",
    ")\n",
    "```\n",
    "\n",
    "The returned run object in this case represents the `parent` (and the **best** result). You can also access the \n",
    "individual child runs (called iterations) in the MLRun UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review the results\n",
    "\n",
    "When running a hyperparam job, the job `results` tab shows the list and marks the best run:\n",
    "\n",
    "<img src=\"./_static/images/hyperparam-results.png\" alt=\"results\" width=\"800\"/>\n",
    "\n",
    "You can also view results by printing the artifact `iteration_results`:\n",
    "\n",
    "```hp_tuning_run.artifact(\"iteration_results\").as_df()```\n",
    "\n",
    "MLRun also generates a `parallel coordinates plot` for the run, you can view it in the MLRun UI.\n",
    "\n",
    "![parallel_coordinates](./_static/images/parallel-coordinates.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "**Base dummy function:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import mlrun"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def hyper_func(context, p1, p2):\n",
    "    print(f\"p1={p1}, p2={p2}, result={p1 * p2}\")\n",
    "    context.log_result(\"multiplier\", p1 * p2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "grid_params = {\"p1\": [2, 4, 1], \"p2\": [10, 20]}\n",
    "task = mlrun.new_task(\"grid-demo\").with_hyper_params(\n",
    "    grid_params, selector=\"max.multiplier\"\n",
    ")\n",
    "run = mlrun.new_function().run(task, handler=hyper_func)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UI Screenshot:**\n",
    "<br><br>\n",
    "<img src=\"_static/images/hyper-params.png\" alt=\"hyper-params\" width=\"800\"/>\n",
    "\n",
    "\n",
    "### Random Search\n",
    "MLRun chooses random parameter combinations. Limit the number of combinations using the `max_iterations` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "grid_params = {\"p1\": [2, 4, 1, 3], \"p2\": [10, 20, 30]}\n",
    "task = mlrun.new_task(\"random-demo\")\n",
    "task.with_hyper_params(\n",
    "    grid_params, selector=\"max.multiplier\", strategy=\"random\", max_iterations=4\n",
    ")\n",
    "run = mlrun.new_function().run(task, handler=hyper_func)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List search\n",
    "\n",
    "This example also shows how to use the `stop_condition` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "list_params = {\"p1\": [2, 3, 7, 4, 5], \"p2\": [15, 10, 10, 20, 30]}\n",
    "task = mlrun.new_task(\"list-demo\").with_hyper_params(\n",
    "    list_params,\n",
    "    selector=\"max.multiplier\",\n",
    "    strategy=\"list\",\n",
    "    stop_condition=\"multiplier>=70\",\n",
    ")\n",
    "run = mlrun.new_function().run(task, handler=hyper_func)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom iterator\n",
    "\n",
    "You can define a child iteration context under the parent/main run. The child run is logged independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "def handler(context: mlrun.MLClientCtx, param_list):\n",
    "    best_multiplier = total = 0\n",
    "    for param in param_list:\n",
    "        with context.get_child_context(**param) as child:\n",
    "            hyper_func(child, **child.parameters)\n",
    "            multiplier = child.results[\"multiplier\"]\n",
    "            total += multiplier\n",
    "            if multiplier > best_multiplier:\n",
    "                child.mark_as_best()\n",
    "                best_multiplier = multiplier\n",
    "\n",
    "    # log result at the parent\n",
    "    context.log_result(\"avg_multiplier\", total / len(param_list))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "param_list = [{\"p1\": 2, \"p2\": 10}, {\"p1\": 3, \"p2\": 30}, {\"p1\": 4, \"p2\": 7}]\n",
    "run = mlrun.new_function().run(handler=handler, params={\"param_list\": param_list})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel execution over containers\n",
    "\n",
    "When working with compute intensive or long running tasks you'll want to run your iterations over a cluster of containers. At the same time, you don't want to bring up too many containers, and you want to limit the number of parallel tasks.\n",
    "\n",
    "MLRun supports distribution of the child runs over Dask or Nuclio clusters. This is handled automatically by MLRun. You only need to deploy the Dask or Nuclio function used by the workers, and set the level of parallelism in the task. The execution can be controlled from the client/notebook, or can have a job (immediate or scheduled) that controls the execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code example (single task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# mark the start of a code section that will be sent to the job\n",
    "# mlrun: start-code"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "import socket\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def hyper_func2(context, data, p1, p2, p3):\n",
    "    print(data.as_df().head())\n",
    "    context.logger.info(f\"p2={p2}, p3={p3}, r1={p2 * p3} at {socket.gethostname()}\")\n",
    "    context.log_result(\"r1\", p2 * p3)\n",
    "    raw_data = {\n",
    "        \"first_name\": [\"Jason\", \"Molly\", \"Tina\", \"Jake\", \"Amy\"],\n",
    "        \"age\": [42, 52, 36, 24, 73],\n",
    "        \"testScore\": [25, 94, 57, 62, 70],\n",
    "    }\n",
    "    df = pd.DataFrame(raw_data, columns=[\"first_name\", \"age\", \"testScore\"])\n",
    "    context.log_dataset(\"mydf\", df=df, stats=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "# mlrun: end-code"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the workers using Dask\n",
    "\n",
    "This example creates a new function and executes the parent/controller as an MLRun `job` and the different child runs over a Dask cluster (MLRun Dask function)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Dask cluster (using MLRun serverless Dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "dask_cluster = mlrun.new_function(\"dask-cluster\", kind=\"dask\", image=\"mlrun/mlrun\")\n",
    "dask_cluster.apply(mlrun.mount_v3io())  # add volume mounts\n",
    "dask_cluster.spec.service_type = \"NodePort\"  # open interface to the dask UI dashboard\n",
    "dask_cluster.spec.replicas = 2  # define two containers\n",
    "uri = dask_cluster.save()\n",
    "uri"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# initialize the dask cluster and get its dashboard url\n",
    "dask_cluster.client"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the parallel work\n",
    "\n",
    "Set the `parallel_runs` attribute to indicate how many child tasks to run in parallel. Set the `dask_cluster_uri` to point \n",
    "to the dask cluster (if it's not set the cluster uri uses dask local). You can also set the `teardown_dask` flag to free up \n",
    "all the dask resources after completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "grid_params = {\"p2\": [2, 1, 4, 1], \"p3\": [10, 20]}\n",
    "task = mlrun.new_task(\n",
    "    params={\"p1\": 8},\n",
    "    inputs={\"data\": \"https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv\"},\n",
    ")\n",
    "task.with_hyper_params(\n",
    "    grid_params,\n",
    "    selector=\"r1\",\n",
    "    strategy=\"grid\",\n",
    "    parallel_runs=4,\n",
    "    dask_cluster_uri=uri,\n",
    "    teardown_dask=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a job that will take the code (using `code_to_function`) and run it over the cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "fn = mlrun.code_to_function(name=\"hyper-tst\", kind=\"job\", image=\"mlrun/mlrun\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "run = fn.run(task, handler=hyper_func2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the workers using Nuclio\n",
    "\n",
    "Nuclio is a high-performance serverless engine that can process many events in parallel. It can also separate initialization from execution. Certain parts of the code (imports, loading data, etc.) can be done once per worker vs. in any run.\n",
    "\n",
    "Nuclio, by default, process events (http, stream, ..). There is a special Nuclio kind that runs MLRun jobs (nuclio:mlrun).\n",
    "\n",
    "```{admonition} Notes\n",
    "* Nuclio tasks are relatively short (preferably under 5 minutes), use it for running many iterations where each individual run is less than 5 min.\n",
    "* Use `context.logger` to drive text outputs (vs `print()`).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a nuclio:mlrun function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "fn = mlrun.code_to_function(name=\"hyper-tst2\", kind=\"nuclio:mlrun\", image=\"mlrun/mlrun\")\n",
    "# replicas * workers need to match or exceed parallel_runs\n",
    "fn.spec.replicas = 2\n",
    "fn.with_http(workers=2)\n",
    "fn.deploy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the parallel task over the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "# this is required to fix Jupyter issue with asyncio (not required outside of Jupyter)\n",
    "# run it only once\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "grid_params = {\"p2\": [2, 1, 4, 1], \"p3\": [10, 20]}\n",
    "task = mlrun.new_task(\n",
    "    params={\"p1\": 8},\n",
    "    inputs={\"data\": \"https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv\"},\n",
    ")\n",
    "task.with_hyper_params(\n",
    "    grid_params, selector=\"r1\", strategy=\"grid\", parallel_runs=4, max_errors=3\n",
    ")\n",
    "run = fn.run(task, handler=hyper_func2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

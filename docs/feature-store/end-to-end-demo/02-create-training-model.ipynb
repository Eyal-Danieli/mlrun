{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training\n",
    "\n",
    "In this part you learn how to use MLRun's **Feature Store** to easily define a **Feature Vector** and create the dataset you need to run the training process.  \n",
    "By the end of this tutorial youâ€™ll learn how to:\n",
    "- Combine multiple data sources to a single feature vector\n",
    "- Create training dataset\n",
    "- Create a model using an MLRun hub function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "project_name = \"fraud-demo\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Create a feature vector  \n",
    "In this section you create a feature vector.  \n",
    "The Feature vector has a `name` so you can reference to it later via the URI or your serving function, and it has a list of \n",
    "`features` from the available feature sets.  You can add a feature from a feature set by adding `<FeatureSet>.<Feature>` to \n",
    "the list, or add `<FeatureSet>.*` to add all the feature set's available features.  \n",
    "\n",
    "By default, the first FeatureSet in the feature list acts as the spine, meaning that all the other features are joined to it.  \n",
    "For example, in this instance you use the early sense sensor data as the spine, so for each early sense event you create produces a row in the resulted feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# Define the list of features to use\n",
    "features = [\n",
    "    \"events.*\",\n",
    "    \"transactions.amount_max_2h\",\n",
    "    \"transactions.amount_sum_2h\",\n",
    "    \"transactions.amount_count_2h\",\n",
    "    \"transactions.amount_avg_2h\",\n",
    "    \"transactions.amount_max_12h\",\n",
    "    \"transactions.amount_sum_12h\",\n",
    "    \"transactions.amount_count_12h\",\n",
    "    \"transactions.amount_avg_12h\",\n",
    "    \"transactions.amount_max_24h\",\n",
    "    \"transactions.amount_sum_24h\",\n",
    "    \"transactions.amount_count_24h\",\n",
    "    \"transactions.amount_avg_24h\",\n",
    "    \"transactions.es_transportation_sum_14d\",\n",
    "    \"transactions.es_health_sum_14d\",\n",
    "    \"transactions.es_otherservices_sum_14d\",\n",
    "    \"transactions.es_food_sum_14d\",\n",
    "    \"transactions.es_hotelservices_sum_14d\",\n",
    "    \"transactions.es_barsandrestaurants_sum_14d\",\n",
    "    \"transactions.es_tech_sum_14d\",\n",
    "    \"transactions.es_sportsandtoys_sum_14d\",\n",
    "    \"transactions.es_wellnessandbeauty_sum_14d\",\n",
    "    \"transactions.es_hyper_sum_14d\",\n",
    "    \"transactions.es_fashion_sum_14d\",\n",
    "    \"transactions.es_home_sum_14d\",\n",
    "    \"transactions.es_travel_sum_14d\",\n",
    "    \"transactions.es_leisure_sum_14d\",\n",
    "    \"transactions.gender_F\",\n",
    "    \"transactions.gender_M\",\n",
    "    \"transactions.step\",\n",
    "    \"transactions.amount\",\n",
    "    \"transactions.timestamp_hour\",\n",
    "    \"transactions.timestamp_day_of_week\",\n",
    "]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the feature vector name for future reference\n",
    "fv_name = \"transactions-fraud\"\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(\n",
    "    fv_name,\n",
    "    features,\n",
    "    label_feature=\"labels.label\",\n",
    "    description=\"Predicting a fraudulent transaction\",\n",
    ")\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Preview the feature vector data\n",
    "\n",
    "Obtain the values of the features in the feature vector, to ensure the data appears as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# Import the Parquet Target so you can directly save your dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "train_dataset = fstore.get_offline_features(fv_name, target=ParquetTarget())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Preview your dataset\n",
    "train_dataset.to_dataframe().tail(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train models and choose the highest accuracy\n",
    "\n",
    "With MLRun, you can easily train different models and compare the results. In the code below, you train three different models.\n",
    "Each one uses a different algorithm (random forest, XGBoost, adabost), and you choose the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# Import the Sklearn classifier function from the functions hub\n",
    "classifier_fn = mlrun.import_function(\"hub://auto_trainer\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# Prepare the parameters list for the training function\n",
    "# you use 3 different models\n",
    "training_params = {\n",
    "    \"model_name\": [\n",
    "        \"transaction_fraud_rf\",\n",
    "        \"transaction_fraud_xgboost\",\n",
    "        \"transaction_fraud_adaboost\",\n",
    "    ],\n",
    "    \"model_class\": [\n",
    "        \"sklearn.ensemble.RandomForestClassifier\",\n",
    "        \"sklearn.ensemble.GradientBoostingClassifier\",\n",
    "        \"sklearn.ensemble.AdaBoostClassifier\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Define the training task, including your feature vector, label and hyperparams definitions\n",
    "train_task = mlrun.new_task(\n",
    "    \"training\",\n",
    "    inputs={\"dataset\": transactions_fv.uri},\n",
    "    params={\"label_columns\": \"label\"},\n",
    ")\n",
    "\n",
    "train_task.with_hyper_params(training_params, strategy=\"list\", selector=\"max.accuracy\")\n",
    "\n",
    "# Specify your cluster image\n",
    "classifier_fn.spec.image = \"mlrun/mlrun\"\n",
    "\n",
    "# Run training\n",
    "classifier_fn.run(train_task, local=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Perform feature selection\n",
    "\n",
    "As part of the data science process, try to reduce the training dataset's size to get rid of bad or unuseful features and save computation time.\n",
    "\n",
    "Use your ready-made feature selection function from MLRun's [`hub://feature_selection`](https://github.com/mlrun/functions/blob/development/feature_selection/feature_selection.ipynb) to select the best features to keep on a sample from your dataset, and run the function on that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "feature_selection_fn = mlrun.import_function(\"hub://feature_selection\")\n",
    "\n",
    "feature_selection_run = feature_selection_fn.run(\n",
    "    params={\n",
    "        \"k\": 18,\n",
    "        \"min_votes\": 2,\n",
    "        \"label_column\": \"label\",\n",
    "        \"output_vector_name\": fv_name + \"-short\",\n",
    "        \"ignore_type_errors\": True,\n",
    "    },\n",
    "    inputs={\"df_artifact\": transactions_fv.uri},\n",
    "    name=\"feature_extraction\",\n",
    "    handler=\"feature_selection\",\n",
    "    local=False,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "mlrun.get_dataitem(feature_selection_run.outputs[\"top_features_vector\"]).as_df().tail(5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Train your models with top features\n",
    "\n",
    "Following the feature selection, you train new models using the resultant features. You can observe that the accuracy \n",
    "and other results remain high,\n",
    "meaning you get a model that requires less features to be accurate and thus less error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# Define your training task, including your feature vector, label and hyperparams definitions\n",
    "ensemble_train_task = mlrun.new_task(\n",
    "    \"training\",\n",
    "    inputs={\"dataset\": feature_selection_run.outputs[\"top_features_vector\"]},\n",
    "    params={\"label_columns\": \"label\"},\n",
    ")\n",
    "ensemble_train_task.with_hyper_params(\n",
    "    training_params, strategy=\"list\", selector=\"max.accuracy\"\n",
    ")\n",
    "\n",
    "classifier_fn.run(ensemble_train_task)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 2 of the model training with the feature store.\n",
    "Proceed to [Part 3](03-deploy-serving-model.html) to learn how to deploy and monitor the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

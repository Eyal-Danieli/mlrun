{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed (multi-function) pipeline example\n",
    "\n",
    "This example demonstrates how to run a pipeline that consists of multiple serverless functions (connected using streams).\n",
    "\n",
    "In the pipeline example the request contains the a URL of a file. It loads the content of the file and breaks it into paragraphs (using the FlatMap class), and pushes the results to a queue/stream. The second function picks up the paragraphs and runs the NLP flow to extract the entities and push the results to the output stream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the stream URLs for the internal queue, the final output and error/exceptions stream:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "streams_prefix = \"v3io:///users/admin/\"\n",
    "internal_stream = streams_prefix + \"in-stream\"\n",
    "out_stream = streams_prefix + \"out-stream\"\n",
    "err_stream = streams_prefix + \"err-stream\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, using Kafka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "kafka_prefix = f\"kafka://{broker}/\"\n",
    "internal_topic = kafka_prefix + \"in-topic\"\n",
    "out_topic = kafka_prefix + \"out-topic\"\n",
    "err_topic = kafka_prefix + \"err-topic\""
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In either case, continue with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# set up the environment\n",
    "import mlrun\n",
    "\n",
    "project = mlrun.get_or_create_project(\"pipe\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# uncomment to install spacy requirements locally\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this example**\n",
    "- [Create the pipeline](#create-the-pipeline)\n",
    "- [Test the pipeline locally](#test-the-pipeline-locally)\n",
    "- [Deploy to the cluster](#deploy-to-the-cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the pipeline\n",
    "\n",
    "The pipeline consists of two functions: data-prep and NLP. Each one has different package dependencies.\n",
    "\n",
    "**Create a file with data-prep graph steps:**\n",
    "\n",
    "```{admonition} Note\n",
    "The `model`, `version` and `operation` can also be specified in the message body \n",
    "to support streaming protocols (e.g. Kafka).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "%%writefile data_prep.py\n",
    "import mlrun\n",
    "import json\n",
    "\n",
    "# load struct from a json file (event points to the url)\n",
    "def load_url(event):\n",
    "    url = event[\"url\"]\n",
    "    data = mlrun.get_object(url).decode(\"utf-8\")\n",
    "    return {\"url\": url, \"doc\": json.loads(data)}\n",
    "\n",
    "def to_paragraphs(event):\n",
    "    paragraphs = []\n",
    "    url = event[\"url\"]\n",
    "    for i, paragraph in enumerate(event[\"doc\"]):\n",
    "        paragraphs.append(\n",
    "            {\"url\": url, \"paragraph_id\": i, \"paragraph\": paragraph}\n",
    "        )\n",
    "    return paragraphs"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a file with NLP graph steps (use spacy):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "%%writefile nlp.py\n",
    "import json\n",
    "import spacy\n",
    "\n",
    "def myprint(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "class ApplyNLP:\n",
    "    def __init__(self, context=None, spacy_dict=\"en_core_web_sm\"):\n",
    "\n",
    "        self.nlp = spacy.load(spacy_dict)\n",
    "\n",
    "    def do(self, paragraph: dict):\n",
    "        tokenized_paragraphs = []\n",
    "        if isinstance(paragraph, (str, bytes)):\n",
    "            paragraph = json.loads(paragraph)\n",
    "        tokenized = {\n",
    "            \"url\": paragraph[\"url\"],\n",
    "            \"paragraph_id\": paragraph[\"paragraph_id\"],\n",
    "            \"tokens\": self.nlp(paragraph[\"paragraph\"]),\n",
    "        }\n",
    "        tokenized_paragraphs.append(tokenized)\n",
    "\n",
    "        return tokenized_paragraphs\n",
    "\n",
    "def extract_entities(tokens):\n",
    "    paragraph_entities = []\n",
    "    for token in tokens:\n",
    "        entities = token[\"tokens\"].ents\n",
    "        for entity in entities:\n",
    "            paragraph_entities.append(\n",
    "                {\n",
    "                    \"url\": token[\"url\"],\n",
    "                    \"paragraph_id\": token[\"paragraph_id\"],\n",
    "                    \"entity\": entity.ents,\n",
    "                }\n",
    "            )\n",
    "    return paragraph_entities\n",
    "\n",
    "def enrich_entities(entities):\n",
    "    enriched_entities = []\n",
    "    for entity in entities:\n",
    "        enriched_entities.append(\n",
    "            {\n",
    "                \"url\": entity[\"url\"],\n",
    "                \"paragraph_id\": entity[\"paragraph_id\"],\n",
    "                \"entity_text\": entity[\"entity\"][0].text,\n",
    "                \"entity_start_char\": entity[\"entity\"][0].start_char,\n",
    "                \"entity_end_char\": entity[\"entity\"][0].end_char,\n",
    "                \"entity_label\": entity[\"entity\"][0].label_,\n",
    "            }\n",
    "        )\n",
    "    return enriched_entities"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build and show the graph:**\n",
    "\n",
    "Create the master function (\"multi-func\") with the `data_prep.py` source and an async graph topology. \n",
    "Add a pipeline of steps made of custom python handlers, classes and built-in classes (like `storey.FlatMap`).\n",
    "\n",
    "The pipeline runs across two functions which are connected by a queue/stream (q1). Use the `function=` to specify which function runs the specified step.\n",
    "End the flow with writing to the output stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# define a new real-time serving function (from code) with an async graph\n",
    "fn = mlrun.code_to_function(\n",
    "    \"multi-func\", filename=\"./data_prep.py\", kind=\"serving\", image=\"mlrun/mlrun\"\n",
    ")\n",
    "graph = fn.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "# define the graph steps (DAG)\n",
    "graph.to(name=\"load_url\", handler=\"load_url\").to(\n",
    "    name=\"to_paragraphs\", handler=\"to_paragraphs\"\n",
    ").to(\"storey.FlatMap\", \"flatten_paragraphs\", _fn=\"(event)\").to(\n",
    "    \">>\", \"q1\", path=internal_stream\n",
    ").to(name=\"nlp\", class_name=\"ApplyNLP\", function=\"enrich\").to(\n",
    "    name=\"extract_entities\", handler=\"extract_entities\", function=\"enrich\"\n",
    ").to(name=\"enrich_entities\", handler=\"enrich_entities\", function=\"enrich\").to(\n",
    "    \"storey.FlatMap\", \"flatten_entities\", _fn=\"(event)\", function=\"enrich\"\n",
    ").to(name=\"printer\", handler=\"myprint\", function=\"enrich\").to(\n",
    "    \">>\", \"output_stream\", path=out_stream\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# specify the \"enrich\" child function, add extra package requirements\n",
    "child = fn.add_child_function(\"enrich\", \"./nlp.py\", \"mlrun/mlrun\")\n",
    "child.spec.build.commands = [\n",
    "    \"python -m pip install spacy\",\n",
    "    \"python -m spacy download en_core_web_sm\",\n",
    "]\n",
    "graph.plot(rankdir=\"LR\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the pipeline locally\n",
    "\n",
    "**Create an input file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "%%writefile in.json\n",
    "[\"Born and raised in Queens, New York City, Trump attended Fordham University for two years and received a bachelor's degree in economics from the Wharton School of the University of Pennsylvania. He became president of his father Fred Trump's real estate business in 1971, renamed it The Trump Organization, and expanded its operations to building or renovating skyscrapers, hotels, casinos, and golf courses. Trump later started various side ventures, mostly by licensing his name. Trump and his businesses have been involved in more than 4,000 state and federal legal actions, including six bankruptcies. He owned the Miss Universe brand of beauty pageants from 1996 to 2015, and produced and hosted the reality television series The Apprentice from 2004 to 2015.\", \n",
    " \"Trump's political positions have been described as populist, protectionist, isolationist, and nationalist. He entered the 2016 presidential race as a Republican and was elected in a surprise electoral college victory over Democratic nominee Hillary Clinton while losing the popular vote.[a] He became the oldest first-term U.S. president[b] and the first without prior military or government service. His election and policies have sparked numerous protests. Trump has made many false or misleading statements during his campaign and presidency. The statements have been documented by fact-checkers, and the media have widely described the phenomenon as unprecedented in American politics. Many of his comments and actions have been characterized as racially charged or racist.\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a mock server (simulator) and test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# tuggle verbosity if needed\n",
    "fn.verbose = False"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "to\n",
    "# create a mock server (simulator), specify to simulate all the functions in the pipeline (\"*\")\n",
    "server = fn.to_mock_server(current_function=\"*\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "# push a sample request into the pipeline and see the results print out (by the printer step)\n",
    "resp = server.test(body={\"url\": \"in.json\"})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "server.wait_for_completion()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "# add credentials to the data/streams\n",
    "fn.apply(mlrun.platforms.v3io_cred())\n",
    "child.apply(mlrun.platforms.v3io_cred())\n",
    "\n",
    "# specify the error stream (to store exceptions from the functions)\n",
    "fn.spec.error_stream = err_stream\n",
    "\n",
    "# deploy as a set of serverless functions\n",
    "fn.deploy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Listen on the output stream**\n",
    "\n",
    "You can use the SDK or CLI to listen on the output stream. Listening should be done in a separate console/notebook. Run:\n",
    "\n",
    "    mlrun watch-stream v3io:///users/admin/out-stream -j\n",
    "\n",
    "or use the SDK:\n",
    "```python\n",
    "from mlrun.platforms import watch_stream\n",
    "watch_stream(\"v3io:///users/admin/out-stream\", is_json=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the live function:**\n",
    "```{Admonition} Note  \n",
    "The url must be a valid path to the input file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "fn.invoke(\"\", body={\"url\": \"v3io:///users/admin/pipe/in.json\"})"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
